{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\n\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":8,"outputs":[{"output_type":"stream","text":"['items.csv', 'sample_submission.csv', 'test.csv', 'sales_train.csv', 'item_categories.csv', 'shops.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Input data which is given in the competition.\nCOMPETITION_DATA_DIRECTORY = '../input/'\nITEMS_FPATH = COMPETITION_DATA_DIRECTORY + 'items.csv'\nSHOPS_FPATH = COMPETITION_DATA_DIRECTORY + 'shops.csv'\nITEM_CATEGORIES_FPATH = COMPETITION_DATA_DIRECTORY + 'item_categories.csv'\n\n# Path where text features will get stored.\nTEXT_FEATURE_FPATH = 'text_features.h5'\n","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"items = pd.read_csv(ITEMS_FPATH)\nitem_categories = pd.read_csv(ITEM_CATEGORIES_FPATH)\nshops = pd.read_csv(SHOPS_FPATH)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_categories.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"        item_category_name  item_category_id\n0  PC - Гарнитуры/Наушники                 0\n1         Аксессуары - PS2                 1\n2         Аксессуары - PS3                 2\n3         Аксессуары - PS4                 3\n4         Аксессуары - PSP                 4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_category_name</th>\n      <th>item_category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PC - Гарнитуры/Наушники</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Аксессуары - PS2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Аксессуары - PS3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Аксессуары - PS4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Аксессуары - PSP</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import normalize\n\n\ndef _get_text_features(names, num_features):\n    tfidf = TfidfVectorizer()\n    features = tfidf.fit_transform(names).toarray()\n    print('Num features from tfidf', features.shape[1])\n    if features.shape[1] <= num_features or features.shape[0] <= num_features:\n        return features.astype(np.float32)\n\n    print('Using NMF')\n    pca = NMF(n_components=num_features)\n    return pca.fit_transform(normalize(features)).astype(np.float32)\n\n\ndef _get_text_feature_df(df, id_col, text_col, num_features):\n    features = _get_text_features(df[text_col].tolist(), num_features)\n    cols = ['{}_text_{}'.format(text_col, i) for i in range(features.shape[1])]\n    output_df = pd.DataFrame(features, columns=cols).astype(np.float32)\n    output_df[id_col] = df[id_col].tolist()\n    return output_df\n\n\ndef get_item_text_features(items_df, num_features):\n    return _get_text_feature_df(items_df, 'item_id', 'item_name', num_features)\n\n\ndef get_shop_text_features(shops_df, num_features):\n    return _get_text_feature_df(shops_df, 'shop_id', 'shop_name', num_features)\n\n\ndef get_category_text_features(categories_df, num_features):\n    return _get_text_feature_df(categories_df, 'item_category_id', 'item_category_name', num_features)\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_category_text_features(item_categories, 100).to_hdf(TEXT_FEATURE_FPATH,'category_tfidf')\nget_category_text_features(item_categories, 60).to_hdf(TEXT_FEATURE_FPATH,'category_60')\n","execution_count":13,"outputs":[{"output_type":"stream","text":"Num features from tfidf 98\nNum features from tfidf 98\nUsing NMF\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_shop_text_features(shops, 100).to_hdf(TEXT_FEATURE_FPATH,'shop_tfidf')\nget_shop_text_features(shops, 50).to_hdf(TEXT_FEATURE_FPATH,'shop_50')\n","execution_count":14,"outputs":[{"output_type":"stream","text":"Num features from tfidf 113\nNum features from tfidf 113\nUsing NMF\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_item_text_features(items, 500).to_hdf(TEXT_FEATURE_FPATH,'item_500')","execution_count":null,"outputs":[{"output_type":"stream","text":"Num features from tfidf 18222\nUsing NMF\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}